{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390dc902-0e65-49c6-b51d-e60c3faa8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a3f343-0dbf-4509-ad44-8a67d58fdb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 10:36:51.071047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aavash/Desktop/envrionments/major_project/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-16 10:36:51.071601: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-16 10:36:51.071641: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aavashl13): /proc/driver/nvidia/version does not exist\n",
      "2022-11-16 10:36:51.072474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    " model = keras.models.load_model('LRCN_model___Date_Time_2022_11_14__14_37_59___Loss_0.21957232058048248___Accuracy_0.9411764740943909.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067d32c1-57dc-4830-91f6-ffdfdc3bcd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading video file\n",
      "The video was successfully saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1668.233] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "# Create an object to read\n",
    "# from camera\n",
    "video = cv2.VideoCapture(-1)\n",
    "\n",
    "# We need to check if camera\n",
    "# is opened previously or not\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Error reading video file\")\n",
    "\n",
    "# We need to set resolutions.\n",
    "# so, convert them from float to integer.\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# Below VideoWriter object will create\n",
    "# a frame of above defined The output\n",
    "# is stored in 'filename.avi' file.\n",
    "result = cv2.VideoWriter('1.MP4',\n",
    "\t\t\t\t\t\tcv2.VideoWriter_fourcc(*'MP4V'),\n",
    "\t\t\t\t\t\t10, size)\n",
    "\t\n",
    "while(True):\n",
    "\tret, frame = video.read()\n",
    "\n",
    "\tif ret == True:\n",
    "\n",
    "\t\t# Write the frame into the\n",
    "\t\t# file 'filename.avi'\n",
    "\t\tresult.write(frame)\n",
    "\n",
    "\t\t# Display the frame\n",
    "\t\t# saved in the file\n",
    "\t\tcv2.imshow('Frame', frame)\n",
    "\n",
    "\t\t# Press S on keyboard\n",
    "\t\t# to stop the process\n",
    "\t\tif cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# Break the loop\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "# When everything done, release\n",
    "# the video capture and video\n",
    "# write objects\n",
    "video.release()\n",
    "result.release()\n",
    "\t\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"The video was successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dda314e-991e-4b1c-8dd4-075a9eff47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    '''\n",
    "    This function will extract the required frames from a video after resizing and normalizing them.\n",
    "    Args:\n",
    "        video_path: The path of the video in the disk, whose frames are to be extracted.\n",
    "    Returns:\n",
    "        frames_list: A list containing the resized and normalized frames of the video.\n",
    "    '''\n",
    " \n",
    "    # Declare a list to store video frames.\n",
    "    frames_list = []\n",
    "    \n",
    "    # Read the Video File using the VideoCapture object.\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    " \n",
    "    # Get the total number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    " \n",
    "    # Calculate the the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    " \n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    " \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    " \n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    " \n",
    "        # Check if Video frame is not successfully read then break the loop\n",
    "        if not success:\n",
    "            break\n",
    " \n",
    "        # Resize the Frame to fixed height and width.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Append the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    # Release the VideoCapture object. \n",
    "    video_reader.release()\n",
    " \n",
    "    # Return the frames list.\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61dcbf60-1ea1-450d-b57f-c5e83234026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_action( SEQUENCE_LENGTH):\n",
    "    '''\n",
    "    This function will perform single action recognition prediction on a video using the LRCN model.\n",
    "    Args:\n",
    "    video_file_path:  The path of the video stored in the disk on which the action recognition is to be performed.\n",
    "    SEQUENCE_LENGTH:  The fixed number of frames of a video that can be passed to the model as one sequence.\n",
    "    '''\n",
    "    video_reader = cv2.VideoCapture(0)\n",
    "    # Initialize the VideoCapture object to read from the video file.\n",
    "    while video_reader.isOpened() : \n",
    "        \n",
    "        if cv2.waitKey(20000) & 0xff == ord('q'):\n",
    "            break\n",
    "        # Get the width and height of the video.\n",
    "        original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Declare a list to store video frames we will extract.\n",
    "        frames_list = []\n",
    "\n",
    "        # Initialize a variable to store the predicted action being performed in the video.\n",
    "        predicted_class_name = ''\n",
    "\n",
    "        # Get the number of frames in the video.\n",
    "        video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Calculate the interval after which frames will be added to the list.\n",
    "        skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
    "\n",
    "        # Iterating the number of times equal to the fixed length of sequence.\n",
    "        for frame_counter in range(SEQUENCE_LENGTH):\n",
    "\n",
    "            # Set the current frame position of the video.\n",
    "            video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "            # Read a frame.\n",
    "            success, frame = video_reader.read() \n",
    "\n",
    "            # Check if frame is not read properly then break the loop.\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Resize the Frame to fixed Dimensions.\n",
    "            resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "\n",
    "            # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1.\n",
    "            normalized_frame = resized_frame / 255\n",
    "\n",
    "            # Appending the pre-processed frame into the frames list\n",
    "            frames_list.append(normalized_frame)\n",
    "\n",
    "        # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
    "        predicted_labels_probabilities = model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
    "\n",
    "        # Get the index of class with highest probability.\n",
    "        predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "\n",
    "        # Get the class name using the retrieved index.\n",
    "        predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "        # Display the predicted action along with the prediction confidence.\n",
    "        print(f'Action Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
    "        \n",
    "    # Release the VideoCapture object. \n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8b2dd59-f83e-4472-bedb-f88aaa956644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1542.656] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "predict_single_action(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504973f-e842-4e9e-9579-b7c78bade5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
